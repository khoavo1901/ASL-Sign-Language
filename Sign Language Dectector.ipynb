{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f150b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37fb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/davidbau/baukit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f1c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a20e96",
   "metadata": {},
   "source": [
    "## Cuting the frame into 48x48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147dba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up the directory to transfer the data to\n",
    "# directory = 'SignImage48x48'\n",
    "# if not os.path.exists(directory):\n",
    "#     os.mkdir(directory)\n",
    "# if not os.path.exists(f'{directory}/blank'):\n",
    "#     os.mkdir(f'{directory}/blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # range 65 to 91 is just the alphabet from A to Z when transform from into character\n",
    "# for i in range(65, 91):\n",
    "#     letter = chr(i)\n",
    "#     if not os.path.exists(f'{directory}/{letter}'):\n",
    "#         os.mkdir(f'{directory}/{letter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d25fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     _, frame = cap.read()\n",
    "#     count = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6bfed",
   "metadata": {},
   "source": [
    "## ASL CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c2eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASL_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ASL_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(512, 512, kernel_size=3)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128, 512)  # Adjust the size accordingly\n",
    "        self.dropout1 = nn.Dropout(p=0.4)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(64, 256)\n",
    "        self.dropout3 = nn.Dropout(p=0.3)\n",
    "        self.fc4 = nn.Linear(256, 64)\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "        self.fc5 = nn.Linear(64, 256)\n",
    "        self.dropout5 = nn.Dropout(p=0.3)\n",
    "        self.fc6 = nn.Linear(256, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        return F.softmax(x, dim=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92764aa5",
   "metadata": {},
   "source": [
    "## Loading the ASL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd100ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfdc699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"aslsigndataset/splitdataset48x48/train\"\n",
    "val_path = \"aslsigndataset/splitdataset48x48/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb8b23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training set = 1473\n"
     ]
    }
   ],
   "source": [
    "train_set = ImageFolder(train_path, transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.Resize((48, 48)),\n",
    "transforms.ToTensor()]))\n",
    "\n",
    "val_set = ImageFolder(val_path, transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.Resize((48, 48)),\n",
    "transforms.ToTensor()]))\n",
    "\n",
    "print(\"Number of images in the training set =\", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dec8311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470th item is a pair (tensor([[[0.8863, 0.7529, 0.7843,  ..., 0.3765, 0.3373, 0.3804],\n",
      "         [0.8706, 0.7843, 0.6863,  ..., 0.2392, 0.2431, 0.3137],\n",
      "         [0.8000, 0.7412, 0.8196,  ..., 0.2392, 0.2275, 0.3020],\n",
      "         ...,\n",
      "         [0.4000, 0.2667, 0.2902,  ..., 0.6196, 0.6275, 0.6549],\n",
      "         [0.3922, 0.2627, 0.2392,  ..., 0.3765, 0.3804, 0.4314],\n",
      "         [0.4471, 0.3294, 0.2706,  ..., 0.4471, 0.4588, 0.5373]]]), 5)\n"
     ]
    }
   ],
   "source": [
    "idx = 1470\n",
    "item = train_set[idx]\n",
    "print(f\"{idx}th item is a pair\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a63ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 48])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1470][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b02643c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size = 128,\n",
    "    shuffle = True,\n",
    "    num_workers=2,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size = 128,\n",
    "    shuffle = True,\n",
    "    num_workers=2,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc42e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape=torch.Size([128, 1, 48, 48]), labels.shape=torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(train_loader.__iter__())\n",
    "print(f\"{images.shape=}, {labels.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72a796e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    # initiate a loss monitor\n",
    "    train_loss = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # predict the class\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        predicted = model(images)\n",
    "        loss = loss_fn(predicted, labels)\n",
    "        correct_predictions += (predicted.argmax(dim=1) == labels).sum().item()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    return np.mean(train_loss), correct_predictions / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcae1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, loss_fn, return_confusion_matrix = False):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    if return_confusion_matrix:\n",
    "        confusion_matrix = torch.zeros(\n",
    "            len(val_loader.dataset.classes), len(val_loader.dataset.classes))\n",
    "        \n",
    "    for images, labels in val_loader:\n",
    "            # predict the class\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            correct_predictions += (predicted.argmax(dim=1) == labels).sum().item() \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_acc = correct_predictions/ len(val_loader.dataset)\n",
    "    \n",
    "    if return_confusion_matrix:\n",
    "        return val_loss, val_acc, confusion_matrix\n",
    "    else:\n",
    "        return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd3e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Conv2d(128, 256, kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(256, 512, kernel_size=3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(512, 512, kernel_size=3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.AdaptiveAvgPool2d(output_size = (1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 512, out_features = 512),  # Adjust the size accordingly\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(64, len(train_set.classes)),\n",
    "            nn.Softmax()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f671ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_network_parameters(model):\n",
    "    tensor_list = list(model.state_dict().items())\n",
    "    total_parameters = 0\n",
    "    print('ModelSummary\\n')\n",
    "    for layer_tensor_name, ternsor in tensor_list:\n",
    "        total_parameters += int(torch.numel(tensor))\n",
    "        print('{}: {} elements'.format(layer_tensor_name, torch.numel(tensor)))\n",
    "    print(f'\\nTotal Trainable Parameters: {total_parameters})!')\n",
    "\n",
    "def view_network_shapes(model, input_shape):\n",
    "    print(summary(model, input_size = input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693a9a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [1, 6]                    --\n",
      "├─Conv2d: 1-1                            [1, 128, 46, 46]          1,280\n",
      "├─BatchNorm2d: 1-2                       [1, 128, 46, 46]          256\n",
      "├─ReLU: 1-3                              [1, 128, 46, 46]          --\n",
      "├─MaxPool2d: 1-4                         [1, 128, 23, 23]          --\n",
      "├─Dropout: 1-5                           [1, 128, 23, 23]          --\n",
      "├─Conv2d: 1-6                            [1, 256, 21, 21]          295,168\n",
      "├─BatchNorm2d: 1-7                       [1, 256, 21, 21]          512\n",
      "├─ReLU: 1-8                              [1, 256, 21, 21]          --\n",
      "├─MaxPool2d: 1-9                         [1, 256, 10, 10]          --\n",
      "├─Conv2d: 1-10                           [1, 512, 8, 8]            1,180,160\n",
      "├─BatchNorm2d: 1-11                      [1, 512, 8, 8]            1,024\n",
      "├─ReLU: 1-12                             [1, 512, 8, 8]            --\n",
      "├─MaxPool2d: 1-13                        [1, 512, 4, 4]            --\n",
      "├─Conv2d: 1-14                           [1, 512, 2, 2]            2,359,808\n",
      "├─BatchNorm2d: 1-15                      [1, 512, 2, 2]            1,024\n",
      "├─ReLU: 1-16                             [1, 512, 2, 2]            --\n",
      "├─MaxPool2d: 1-17                        [1, 512, 1, 1]            --\n",
      "├─AdaptiveAvgPool2d: 1-18                [1, 512, 1, 1]            --\n",
      "├─Flatten: 1-19                          [1, 512]                  --\n",
      "├─Linear: 1-20                           [1, 512]                  262,656\n",
      "├─ReLU: 1-21                             [1, 512]                  --\n",
      "├─Dropout: 1-22                          [1, 512]                  --\n",
      "├─Linear: 1-23                           [1, 64]                   32,832\n",
      "├─ReLU: 1-24                             [1, 64]                   --\n",
      "├─Dropout: 1-25                          [1, 64]                   --\n",
      "├─Linear: 1-26                           [1, 256]                  16,640\n",
      "├─ReLU: 1-27                             [1, 256]                  --\n",
      "├─Dropout: 1-28                          [1, 256]                  --\n",
      "├─Linear: 1-29                           [1, 128]                  32,896\n",
      "├─ReLU: 1-30                             [1, 128]                  --\n",
      "├─Dropout: 1-31                          [1, 128]                  --\n",
      "├─Linear: 1-32                           [1, 64]                   8,256\n",
      "├─ReLU: 1-33                             [1, 64]                   --\n",
      "├─Dropout: 1-34                          [1, 64]                   --\n",
      "├─Linear: 1-35                           [1, 6]                    390\n",
      "├─Softmax: 1-36                          [1, 6]                    --\n",
      "==========================================================================================\n",
      "Total params: 4,192,902\n",
      "Trainable params: 4,192,902\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 218.20\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.71\n",
      "Params size (MB): 16.77\n",
      "Estimated Total Size (MB): 23.49\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1,1,48,48)\n",
    "view_network_shapes(model, torch.randn(input_shape).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ef485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:06<10:43,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100 | train loss=1.1000, train_acc=0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:13<10:38,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/100 | train loss=1.0917, train_acc=0.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:19<10:36,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/100 | train loss=1.0901, train_acc=0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:26<10:24,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/100 | train loss=1.0885, train_acc=0.9593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:32<10:15,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/100 | train loss=1.0907, train_acc=0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:39<10:13,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/100 | train loss=1.0797, train_acc=0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:45<10:07,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/100 | train loss=1.0860, train_acc=0.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:52<10:04,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/100 | train loss=1.0814, train_acc=0.9647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:58<09:59,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/100 | train loss=1.0861, train_acc=0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [01:05<09:51,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100 | train loss=1.0842, train_acc=0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [01:12<09:47,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/100 | train loss=1.0713, train_acc=0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [01:18<09:45,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12/100 | train loss=1.0818, train_acc=0.9661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [01:25<09:36,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13/100 | train loss=1.0837, train_acc=0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [01:32<09:29,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14/100 | train loss=1.0748, train_acc=0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [01:38<09:27,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15/100 | train loss=1.0704, train_acc=0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [01:45<09:22,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16/100 | train loss=1.0688, train_acc=0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:52<09:16,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17/100 | train loss=1.0694, train_acc=0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:59<09:14,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18/100 | train loss=1.0718, train_acc=0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [02:06<09:09,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19/100 | train loss=1.0681, train_acc=0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [02:12<08:59,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20/100 | train loss=1.0724, train_acc=0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [02:19<08:53,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21/100 | train loss=1.0684, train_acc=0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [02:26<08:43,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22/100 | train loss=1.0716, train_acc=0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [02:33<08:47,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23/100 | train loss=1.0742, train_acc=0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [02:40<08:43,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24/100 | train loss=1.0690, train_acc=0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [02:47<08:36,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25/100 | train loss=1.0725, train_acc=0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [02:54<08:31,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26/100 | train loss=1.0735, train_acc=0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [03:00<08:20,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27/100 | train loss=1.0693, train_acc=0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [03:07<08:03,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28/100 | train loss=1.0689, train_acc=0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [03:13<07:56,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29/100 | train loss=1.0669, train_acc=0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [03:20<07:50,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30/100 | train loss=1.0673, train_acc=0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [03:27<07:39,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31/100 | train loss=1.0641, train_acc=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [03:33<07:28,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32/100 | train loss=1.0649, train_acc=0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [03:39<07:17,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33/100 | train loss=1.0653, train_acc=0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [03:46<07:08,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34/100 | train loss=1.0699, train_acc=0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [03:52<07:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35/100 | train loss=1.0637, train_acc=0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [03:59<06:51,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36/100 | train loss=1.0635, train_acc=0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [04:05<06:44,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37/100 | train loss=1.0674, train_acc=0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [04:12<06:38,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38/100 | train loss=1.0680, train_acc=0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [04:18<06:31,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39/100 | train loss=1.0622, train_acc=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [04:24<06:24,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40/100 | train loss=1.0641, train_acc=0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [04:31<06:17,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41/100 | train loss=1.0682, train_acc=0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [04:37<06:11,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42/100 | train loss=1.0634, train_acc=0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [04:43<06:04,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43/100 | train loss=1.0617, train_acc=0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [04:50<05:59,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44/100 | train loss=1.0659, train_acc=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [04:56<05:51,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45/100 | train loss=1.0634, train_acc=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [05:03<05:45,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46/100 | train loss=1.0665, train_acc=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [05:09<05:39,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47/100 | train loss=1.0659, train_acc=0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [05:15<05:32,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48/100 | train loss=1.0646, train_acc=0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [05:22<05:26,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49/100 | train loss=1.0610, train_acc=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [05:28<05:19,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50/100 | train loss=1.0615, train_acc=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [05:35<05:12,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51/100 | train loss=1.0620, train_acc=0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [05:41<05:07,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52/100 | train loss=1.0595, train_acc=0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [05:47<05:00,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53/100 | train loss=1.0594, train_acc=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [05:54<04:54,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54/100 | train loss=1.0621, train_acc=0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [06:00<04:47,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55/100 | train loss=1.0617, train_acc=0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [06:07<04:42,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56/100 | train loss=1.0626, train_acc=0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [06:13<04:37,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57/100 | train loss=1.0646, train_acc=0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [06:20<04:34,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58/100 | train loss=1.0560, train_acc=0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [06:26<04:27,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59/100 | train loss=1.0611, train_acc=0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [06:33<04:18,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60/100 | train loss=1.0593, train_acc=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [06:40<04:17,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61/100 | train loss=1.0574, train_acc=0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [06:46<04:12,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62/100 | train loss=1.0571, train_acc=0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [06:49<04:11,  6.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m training_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m---> 11\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, loss_fn, optimizer)\n\u001b[0;32m     12\u001b[0m     training_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(train_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m=:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# predict the class\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m w\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context\u001b[38;5;241m.\u001b[39mget_context()\u001b[38;5;241m.\u001b[39mProcess\u001b[38;5;241m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(process_obj, to_child)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[38;5;241m.\u001b[39mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = ASL_Model(len(train_set.classes)).to(device)\n",
    "epochs = 120\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "training_losses = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_model(model, train_loader, loss_fn, optimizer)\n",
    "    training_losses.append(train_loss)\n",
    "    print(f\"epoch {epoch+1}/{epochs} | train loss={np.mean(train_loss):.4f}, {train_acc=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6efcb17",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "File archive cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\serialization.py:627\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    624\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    628\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\serialization.py:501\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mC:\\Anaconda\\Lib\\site-packages\\torch\\serialization.py:472\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: File archive cannot be opened."
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/Chem's bbi/Downloads/ASL-Sign-Language\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3edd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
